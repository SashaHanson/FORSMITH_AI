{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2763e59",
   "metadata": {},
   "source": [
    "\n",
    "# Roof Defect Classifier — DINOv2 ViT‑S/14 + Symmetric Cross‑Entropy (SCE)\n",
    "\n",
    "This notebook fine‑tunes a **DINOv2 ViT‑S/14** encoder for **single‑head defect classification** on your ~2k in‑domain report images.\n",
    "\n",
    "**What you get**\n",
    "- Noise‑robust training via **Symmetric Cross‑Entropy (SCE)**\n",
    "- **MixUp/CutMix** (timm) + light spatial/photometric augs\n",
    "- **Class‑balanced sampling** (optional)\n",
    "- **Grouped split** by `group` (report/building) when available\n",
    "- Early stop on **macro‑F1**\n",
    "- Saved artifacts: best checkpoint, per‑epoch metrics, confusion matrix, label mapping\n",
    "\n",
    "Works in **Colab** and **Vertex AI Workbench**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe14e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %%capture\n",
    "# If running in Colab/Vertex AI for the first time, uncomment:\n",
    "# !pip install -U torch torchvision timm pandas scikit-learn numpy pillow\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc1a6601",
   "metadata": {},
   "source": [
    "## 1) Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94504010",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pathlib import Path\n",
    "\n",
    "# --- Required: path to your CSV (columns: path,label[,group]) ---\n",
    "CSV_PATH = \"dataset.csv\"  # change to your CSV\n",
    "\n",
    "# If paths in the CSV are relative, this prefix will be prepended\n",
    "IMG_ROOT = \".\"\n",
    "\n",
    "# Output directory for checkpoints & reports\n",
    "OUTDIR = \"runs/vits14_sce_colab\"\n",
    "\n",
    "# Training hyperparams\n",
    "IMG_SIZE = 288\n",
    "EPOCHS = 80\n",
    "BATCH_SIZE = 32\n",
    "NUM_WORKERS = 4\n",
    "VAL_FRAC = 0.2\n",
    "USE_GROUPS = True         # set False if you don't have a 'group' column\n",
    "BALANCED_SAMPLER = True   # class-balanced sampling\n",
    "MIXUP = 0.1               # 0.0 to disable\n",
    "CUTMIX = 0.1              # 0.0 to disable\n",
    "\n",
    "# Loss (SCE) params\n",
    "SCE_ALPHA = 0.1\n",
    "SCE_BETA  = 1.0\n",
    "LABEL_SMOOTH = 0.0        # optional smoothing inside SCE\n",
    "\n",
    "# Optim schedule\n",
    "LR = 5e-4\n",
    "WARMUP_EPOCHS = 3.0\n",
    "WEIGHT_DECAY = 1e-4\n",
    "DROP_PATH = 0.1\n",
    "EARLY_STOP_PATIENCE = 10\n",
    "SEED = 42\n",
    "\n",
    "Path(OUTDIR).mkdir(parents=True, exist_ok=True)\n",
    "print(\"Saving outputs to:\", OUTDIR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c98b731",
   "metadata": {},
   "source": [
    "## 2) Imports & Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3584212",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os, math, json, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "\n",
    "import timm\n",
    "from timm.data.mixup import Mixup\n",
    "\n",
    "from sklearn.model_selection import GroupShuffleSplit, StratifiedShuffleSplit\n",
    "from sklearn.metrics import f1_score, classification_report, confusion_matrix\n",
    "\n",
    "def set_seed(seed: int = 42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "def one_hot(labels: torch.Tensor, num_classes: int) -> torch.Tensor:\n",
    "    return F.one_hot(labels.long(), num_classes=num_classes).float()\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Device:\", device)\n",
    "set_seed(SEED)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de0b958",
   "metadata": {},
   "source": [
    "## 3) Dataset loader (from CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919b2bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CSVImageDataset(Dataset):\n",
    "    def __init__(self, df: pd.DataFrame, img_root: str, img_size: int, is_train: bool):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.img_root = img_root\n",
    "        self.is_train = is_train\n",
    "        self.img_size = img_size\n",
    "\n",
    "        # Basic transforms — keep spatial aug light; MixUp/CutMix handles label-level reg\n",
    "        import torchvision.transforms as T\n",
    "        if is_train:\n",
    "            self.tf = T.Compose([\n",
    "                T.Resize(int(img_size * 1.15)),\n",
    "                T.RandomResizedCrop(img_size, scale=(0.7, 1.0)),\n",
    "                T.RandomHorizontalFlip(p=0.5),\n",
    "                T.RandomPerspective(distortion_scale=0.05, p=0.2),\n",
    "                T.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.05, hue=0.02),\n",
    "                T.ToTensor(),\n",
    "                T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "            ])\n",
    "        else:\n",
    "            self.tf = T.Compose([\n",
    "                T.Resize(int(img_size * 1.05)),\n",
    "                T.CenterCrop(img_size),\n",
    "                T.ToTensor(),\n",
    "                T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "            ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        row = self.df.iloc[idx]\n",
    "        path = row[\"path\"]\n",
    "        if not os.path.isabs(path):\n",
    "            path = os.path.join(self.img_root, path)\n",
    "        img = Image.open(path).convert(\"RGB\")\n",
    "        img = self.tf(img)\n",
    "        label = int(row[\"y\"])\n",
    "        return img, label\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "686be7c6",
   "metadata": {},
   "source": [
    "## 4) Symmetric Cross‑Entropy (SCE) loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79730f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class SCELoss(nn.Module):\n",
    "    \"\"\"Symmetric Cross Entropy:\n",
    "       SCE = alpha * CE(t,p) + beta * RCE(t,p)\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes: int, alpha: float = 0.1, beta: float = 1.0, label_smooth: float = 0.0, eps: float = 1e-4):\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.label_smooth = label_smooth\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, logits: torch.Tensor, target: torch.Tensor) -> torch.Tensor:\n",
    "        log_probs = F.log_softmax(logits, dim=1)\n",
    "        probs = log_probs.exp()\n",
    "\n",
    "        if target.dim() == 1:\n",
    "            t = one_hot(target, logits.size(1))\n",
    "            if self.label_smooth > 0:\n",
    "                t = t * (1.0 - self.label_smooth) + self.label_smooth / self.num_classes\n",
    "        else:\n",
    "            t = target\n",
    "        t = t.clamp(self.eps, 1.0)\n",
    "\n",
    "        ce = -(t * log_probs).sum(dim=1).mean()\n",
    "        rce = -(probs * torch.log(t)).sum(dim=1).mean()\n",
    "        return self.alpha * ce + self.beta * rce\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cedf79d9",
   "metadata": {},
   "source": [
    "## 5) Model: DINOv2 ViT‑S/14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac019dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_model(num_classes: int, drop_path: float = 0.1):\n",
    "    model = timm.create_model(\n",
    "        \"vit_small_patch14_dinov2.lvd142m\",\n",
    "        pretrained=True,\n",
    "        num_classes=num_classes,\n",
    "        drop_path_rate=drop_path,\n",
    "    )\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74bd611a",
   "metadata": {},
   "source": [
    "## 6) Class‑balanced sampler (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04d7f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def make_weighted_sampler(labels: np.ndarray) -> WeightedRandomSampler:\n",
    "    unique, counts = np.unique(labels, return_counts=True)\n",
    "    freq = {int(k): int(v) for k, v in zip(unique, counts)}\n",
    "    weights = np.array([1.0 / freq[int(y)] for y in labels], dtype=np.float32)\n",
    "    sampler = WeightedRandomSampler(weights.tolist(), num_samples=len(labels), replacement=True)\n",
    "    return sampler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab6a6ff2",
   "metadata": {},
   "source": [
    "## 7) Train/Eval helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3470d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, loader, device, num_classes: int):\n",
    "    model.eval()\n",
    "    all_logits, all_targets = [], []\n",
    "    for imgs, labels in loader:\n",
    "        imgs = imgs.to(device, non_blocking=True)\n",
    "        labels = labels.to(device, non_blocking=True)\n",
    "        logits = model(imgs)\n",
    "        all_logits.append(logits.cpu())\n",
    "        all_targets.append(labels.cpu())\n",
    "    logits = torch.cat(all_logits, dim=0)\n",
    "    targets = torch.cat(all_targets, dim=0).numpy()\n",
    "    probs = torch.softmax(logits, dim=1).numpy()\n",
    "    preds = probs.argmax(axis=1)\n",
    "    top1 = (preds == targets).mean().item()\n",
    "    top3 = np.mean([t in np.argpartition(p, -3)[-3:] for p, t in zip(probs, targets)]).item()\n",
    "    macro_f1 = f1_score(targets, preds, average=\"macro\")\n",
    "    return top1, top3, macro_f1, preds, targets\n",
    "\n",
    "def cosine_warmup_scheduler(optimizer, total_steps, warmup_steps):\n",
    "    def lr_lambda(step):\n",
    "        if step < warmup_steps:\n",
    "            return float(step + 1) / float(max(1, warmup_steps))\n",
    "        progress = (step - warmup_steps) / max(1, total_steps - warmup_steps)\n",
    "        return 0.5 * (1.0 + math.cos(math.pi * progress))\n",
    "    return torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lr_lambda)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f28e1aa8",
   "metadata": {},
   "source": [
    "## 8) Load CSV, map labels, and split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd78f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "assert \"path\" in df.columns and \"label\" in df.columns, \"CSV must include columns: path,label[,group]\"\n",
    "\n",
    "# Drop unlabeled rows (blank/NaN)\n",
    "df = df[df[\"label\"].astype(str).str.len() > 0].copy()\n",
    "\n",
    "# Label mapping\n",
    "classes = sorted(df[\"label\"].dropna().unique().tolist())\n",
    "class_to_idx = {c: i for i, c in enumerate(classes)}\n",
    "df[\"y\"] = df[\"label\"].map(class_to_idx).astype(int)\n",
    "\n",
    "with open(os.path.join(OUTDIR, \"label_to_index.json\"), \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(class_to_idx, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(\"Classes:\", len(classes))\n",
    "print(\"Example classes:\", classes[:10])\n",
    "\n",
    "# Grouped split if requested & available\n",
    "if USE_GROUPS and \"group\" in df.columns:\n",
    "    gss = GroupShuffleSplit(n_splits=1, test_size=VAL_FRAC, random_state=SEED)\n",
    "    train_idx, val_idx = next(gss.split(df, groups=df[\"group\"]))\n",
    "else:\n",
    "    sss = StratifiedShuffleSplit(n_splits=1, test_size=VAL_FRAC, random_state=SEED)\n",
    "    train_idx, val_idx = next(sss.split(df, df[\"y\"]))\n",
    "\n",
    "df_train = df.iloc[train_idx].reset_index(drop=True)\n",
    "df_val   = df.iloc[val_idx].reset_index(drop=True)\n",
    "\n",
    "print(f\"Train: {len(df_train)} | Val: {len(df_val)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03277354",
   "metadata": {},
   "source": [
    "## 9) Build datasets and dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9cc5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ds_train = CSVImageDataset(df_train, IMG_ROOT, IMG_SIZE, is_train=True)\n",
    "ds_val   = CSVImageDataset(df_val,   IMG_ROOT, IMG_SIZE, is_train=False)\n",
    "\n",
    "if BALANCED_SAMPLER:\n",
    "    sampler = make_weighted_sampler(df_train[\"y\"].values)\n",
    "    train_loader = DataLoader(ds_train, batch_size=BATCH_SIZE, sampler=sampler,\n",
    "                              num_workers=NUM_WORKERS, pin_memory=True, drop_last=True)\n",
    "else:\n",
    "    train_loader = DataLoader(ds_train, batch_size=BATCH_SIZE, shuffle=True,\n",
    "                              num_workers=NUM_WORKERS, pin_memory=True, drop_last=True)\n",
    "\n",
    "val_loader = DataLoader(ds_val, batch_size=BATCH_SIZE, shuffle=False,\n",
    "                        num_workers=NUM_WORKERS, pin_memory=True)\n",
    "\n",
    "len(train_loader), len(val_loader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d209d2b7",
   "metadata": {},
   "source": [
    "## 10) Initialize model, optimizer, scheduler, loss, mixup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4505fac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_classes = len(classes)\n",
    "model = create_model(num_classes=num_classes, drop_path=DROP_PATH).to(device)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
    "\n",
    "total_steps = max(1, len(train_loader) * EPOCHS)\n",
    "warmup_steps = int(WARMUP_EPOCHS * len(train_loader))\n",
    "scheduler = cosine_warmup_scheduler(optimizer, total_steps, warmup_steps)\n",
    "\n",
    "criterion = SCELoss(num_classes=num_classes, alpha=SCE_ALPHA, beta=SCE_BETA, label_smooth=LABEL_SMOOTH)\n",
    "\n",
    "mixup_fn = None\n",
    "if MIXUP > 0.0 or CUTMIX > 0.0:\n",
    "    mixup_fn = Mixup(\n",
    "        mixup_alpha=MIXUP,\n",
    "        cutmix_alpha=CUTMIX,\n",
    "        label_smoothing=0.0,\n",
    "        num_classes=num_classes\n",
    "    )\n",
    "\n",
    "print(\"Model ready.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bfb7182",
   "metadata": {},
   "source": [
    "## 11) Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cfaca14",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "history = []\n",
    "best_f1 = -1.0\n",
    "best_ckpt = os.path.join(OUTDIR, \"best.pth\")\n",
    "epochs_no_improve = 0\n",
    "\n",
    "global_step = 0\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    n_seen = 0\n",
    "\n",
    "    for imgs, labels in train_loader:\n",
    "        imgs = imgs.to(device, non_blocking=True)\n",
    "        labels = labels.to(device, non_blocking=True)\n",
    "\n",
    "        if mixup_fn is not None:\n",
    "            imgs, targets = mixup_fn(imgs, labels)  # soft labels\n",
    "        else:\n",
    "            targets = labels                        # hard labels\n",
    "\n",
    "        logits = model(imgs)\n",
    "        loss = criterion(logits, targets)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        bs = imgs.size(0)\n",
    "        running_loss += loss.item() * bs\n",
    "        n_seen += bs\n",
    "        global_step += 1\n",
    "\n",
    "    train_loss = running_loss / max(1, n_seen)\n",
    "\n",
    "    # Eval\n",
    "    top1, top3, macro_f1, preds, targets_np = evaluate(model, val_loader, device, num_classes)\n",
    "    print(f\"Epoch {epoch:03d} | train_loss {train_loss:.4f} | val_top1 {top1*100:.2f}% | val_top3 {top3*100:.2f}% | macroF1 {macro_f1*100:.2f}%\")\n",
    "\n",
    "    history.append({\n",
    "        \"epoch\": epoch,\n",
    "        \"train_loss\": float(train_loss),\n",
    "        \"val_top1\": float(top1),\n",
    "        \"val_top3\": float(top3),\n",
    "        \"val_macro_f1\": float(macro_f1),\n",
    "        \"lr\": float(optimizer.param_groups[0][\"lr\"]),\n",
    "    })\n",
    "    pd.DataFrame(history).to_csv(os.path.join(OUTDIR, \"training_log.csv\"), index=False)\n",
    "\n",
    "    if macro_f1 > best_f1 + 1e-6:\n",
    "        best_f1 = macro_f1\n",
    "        epochs_no_improve = 0\n",
    "        torch.save({\"model\": model.state_dict(),\n",
    "                    \"classes\": classes,\n",
    "                    \"config\": {\n",
    "                        \"CSV_PATH\": CSV_PATH, \"IMG_ROOT\": IMG_ROOT, \"IMG_SIZE\": IMG_SIZE\n",
    "                    }}, best_ckpt)\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "        if epochs_no_improve >= EARLY_STOP_PATIENCE:\n",
    "            print(f\"Early stopping at epoch {epoch}. Best macro-F1: {best_f1*100:.2f}%\")\n",
    "            break\n",
    "\n",
    "print(\"Best macro-F1:\", round(best_f1*100, 2), \"%\")\n",
    "print(\"Checkpoint:\", best_ckpt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22411d33",
   "metadata": {},
   "source": [
    "## 12) Final evaluation and reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e11672",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load best\n",
    "ckpt = torch.load(best_ckpt, map_location=\"cpu\")\n",
    "model.load_state_dict(ckpt[\"model\"])\n",
    "\n",
    "top1, top3, macro_f1, preds, targets_np = evaluate(model, val_loader, device, num_classes)\n",
    "print(f\"VAL  Top-1: {top1*100:.2f}%  | Top-3: {top3*100:.2f}%  | Macro-F1: {macro_f1*100:.2f}%\")\n",
    "\n",
    "# Classification report\n",
    "rep = classification_report(targets_np, preds, target_names=classes, digits=4, zero_division=0)\n",
    "print(rep)\n",
    "with open(os.path.join(OUTDIR, \"val_classification_report.txt\"), \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(rep)\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(targets_np, preds, labels=list(range(num_classes)))\n",
    "cm_df = pd.DataFrame(cm, index=classes, columns=classes)\n",
    "cm_csv = os.path.join(OUTDIR, \"val_confusion_matrix.csv\")\n",
    "cm_df.to_csv(cm_csv)\n",
    "\n",
    "print(\"Saved:\")\n",
    "print(\" - training log:\", os.path.join(OUTDIR, \"training_log.csv\"))\n",
    "print(\" - classification report:\", os.path.join(OUTDIR, \"val_classification_report.txt\"))\n",
    "print(\" - confusion matrix:\", cm_csv)\n",
    "print(\" - label mapping:\", os.path.join(OUTDIR, \"label_to_index.json\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b9cc5fa",
   "metadata": {},
   "source": [
    "## 13) (Optional) Export artifacts to Google Cloud Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea4c44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# If you're on Colab/Vertex and want to push results to GCS:\n",
    "# 1) Set your bucket\n",
    "# GCS_BUCKET = \"gs://your-bucket-name/roof-defect-runs\"\n",
    "#\n",
    "# 2) If on Colab:\n",
    "# from google.colab import auth\n",
    "# auth.authenticate_user()\n",
    "#\n",
    "# 3) Copy\n",
    "# !gsutil -m cp -r $OUTDIR $GCS_BUCKET\n",
    "#\n",
    "# Or use the Python client:\n",
    "# from google.cloud import storage\n",
    "# client = storage.Client()\n",
    "# bucket = client.bucket(GCS_BUCKET.replace(\"gs://\",\"\"))\n",
    "# for path in Path(OUTDIR).glob(\"**/*\"):\n",
    "#     if path.is_file():\n",
    "#         blob = bucket.blob(str(Path(OUTDIR).name / path.relative_to(OUTDIR)))\n",
    "#         blob.upload_from_filename(str(path))\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
