{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d454f55",
   "metadata": {},
   "source": [
    "# FORSMITH Roof Image Classifier — ViT (DINOv2) Fine‑Tuning\n",
    "\n",
    "**Objective:** Train a model that takes a roof image and predicts the correct `observation_id` (class) from the `forsmith_roof_labels.json` taxonomy.  \n",
    "**Artifacts:** `model_best.pt`, `label_map.json`, `calibration.json`, `metrics.json`, ONNX export (optional), and an inference wrapper with optional **sheet-aware** masking.\n",
    "\n",
    "> Dataset: 1,616 images. CSV columns required: `image_file`, `label`, `observation_id`. The filename contains `report_id` as `<report_id>_pageXX_imgY.png`, enabling **GroupKFold** by report to avoid leakage.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "707ec3f3-7673-4b96-89aa-63a382e31dc9",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Section 0 - Dependency Installs\n",
    "Ensures all required Python packages are available inside the Vertex AI Workbench kernel. Missing dependencies (Albumentations, timm, OpenCV, scikit-learn, torchmetrics, and the Google Cloud Storage client) are installed into the local `_deps` directory so future cells can import them without elevated permissions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff595bc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch: 2.5.1+cu121\n",
      "torchvision: 0.20.1+cu121\n",
      "torchaudio: 2.5.1+cu121\n",
      "numpy: 2.1.2\n",
      "cuda available: False\n"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# ### Environment setup (Pinned versions for CUDA 12.1)\n",
    "# This cell ensures `torch`, `torchvision`, `torchaudio`, and `numpy` are mutually compatible.\n",
    "# - torch/vision/audio = 2.5.1 / 0.20.1 / 2.5.1 (cu121 wheels)\n",
    "# - numpy < 2.2 (e.g., 2.1.4) to satisfy numba 0.61 and ydata-profiling.\n",
    "# If your runtime has a different CUDA minor (e.g., 12.2), change `cu121` to `cu122`.\n",
    "\n",
    "# %%\n",
    "# 0) Inspect GPU\n",
    "\n",
    "\n",
    "# 1) Remove mismatched wheels\n",
    "!pip -q uninstall -y numpy || true\n",
    "\n",
    "# 2) Install compatible triplet and safe numpy\n",
    "!pip -q install --index-url https://download.pytorch.org/whl/cu121   torch==2.5.1 torchvision==0.20.1 torchaudio==2.5.1\n",
    "!pip -q install \"numpy<2.2\"\n",
    "\n",
    "# 3) Print versions\n",
    "import torch, torchvision, torchaudio, numpy as _np\n",
    "print(\"torch:\", torch.__version__)\n",
    "print(\"torchvision:\", torchvision.__version__)\n",
    "print(\"torchaudio:\", torchaudio.__version__)\n",
    "print(\"numpy:\", _np.__version__)\n",
    "print(\"cuda available:\", torch.cuda.is_available())\n",
    "\n",
    "# (Optional) If you rely on torchmetrics, install a version known to pair with torch 2.5.x\n",
    "# !pip -q install torchmetrics==1.4.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eeedd002",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK - matmul result shape: torch.Size([1024, 1024]) on device: cpu\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# Quick sanity check for CUDA tensor ops\n",
    "import torch\n",
    "x = torch.randn(1024, 1024, device='cuda' if torch.cuda.is_available() else 'cpu')\n",
    "y = x @ x.T\n",
    "print(\"OK - matmul result shape:\", y.shape, \"on device:\", y.device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "729cc4c2",
   "metadata": {},
   "source": [
    "### Section 1 - Configuration & Paths\n",
    "Defines the master `CONFIG` dictionary: Cloud Storage locations for images and labels, the local cache directory, runtime hyperparameters, and inference flags. Update these values to point at new buckets, prefixes, or experiment settings before running the pipeline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c50bb2b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'GCS_BUCKET': 'forsmith-report-bucket', 'GCS_IMAGES_PREFIX': 'images/', 'GCS_LABELS_CSV': 'labels/labels.csv', 'GCS_LABELS_JSON': 'labels/forsmith_roof_labels.json', 'DATA_ROOT': '/home/jupyter/forsmith_roof_data', 'IMAGES_DIR': '/home/jupyter/forsmith_roof_data/images', 'CSV_PATH': '/home/jupyter/forsmith_roof_data/labels.csv', 'LABELS_JSON': '/home/jupyter/forsmith_roof_data/forsmith_roof_labels.json', 'SEED': 1337, 'IMAGE_SIZE': 518, 'BATCH_SIZE': 16, 'ACCUM_STEPS': 1, 'EPOCHS_LINPROBE': 8, 'EPOCHS_UNFREEZE': 20, 'EPOCHS_FULLFT': 10, 'BASE_LR': 0.0002, 'WEIGHT_DECAY': 0.05, 'WARMUP_PCT': 0.05, 'LABEL_SMOOTH': 0.1, 'USE_AMP': True, 'N_SPLITS': 5, 'FOLD_INDEX': 0, 'TEST_SIZE': 0.15, 'OUT_DIR': '/home/jupyter/forsmith_roof_data/outputs', 'SAVE_ON_BEST': 'macro_f1', 'ENABLE_SHEET_MASK': True}\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# 1) CONFIG & ENVIRONMENT\n",
    "# =========================\n",
    "from pathlib import Path\n",
    "\n",
    "DATA_ROOT = Path('/home/jupyter/forsmith_roof_data')\n",
    "\n",
    "CONFIG = {\n",
    "    # Cloud Storage locations\n",
    "    'GCS_BUCKET': 'forsmith-report-bucket',\n",
    "    'GCS_IMAGES_PREFIX': 'images/',\n",
    "    'GCS_LABELS_CSV': 'labels/labels.csv',\n",
    "    'GCS_LABELS_JSON': 'labels/forsmith_roof_labels.json',  # update if your JSON lives elsewhere\n",
    "\n",
    "    # Paths on the notebook instance (populated from GCS)\n",
    "    'DATA_ROOT': str(DATA_ROOT),\n",
    "    'IMAGES_DIR': str(DATA_ROOT / 'images'),\n",
    "    'CSV_PATH': str(DATA_ROOT / 'labels.csv'),\n",
    "    'LABELS_JSON': str(DATA_ROOT / 'forsmith_roof_labels.json'),\n",
    "\n",
    "    # Run control\n",
    "    'SEED': 1337,\n",
    "    'IMAGE_SIZE': 518,\n",
    "    'BATCH_SIZE': 16,\n",
    "    'ACCUM_STEPS': 1,\n",
    "    'EPOCHS_LINPROBE': 8,\n",
    "    'EPOCHS_UNFREEZE': 20,\n",
    "    'EPOCHS_FULLFT': 10,\n",
    "    'BASE_LR': 2e-4,\n",
    "    'WEIGHT_DECAY': 0.05,\n",
    "    'WARMUP_PCT': 0.05,\n",
    "    'LABEL_SMOOTH': 0.1,\n",
    "    'USE_AMP': True,\n",
    "\n",
    "    # Cross-validation\n",
    "    'N_SPLITS': 5,\n",
    "    'FOLD_INDEX': 0,\n",
    "    'TEST_SIZE': 0.15,\n",
    "\n",
    "    # Checkpointing\n",
    "    'OUT_DIR': str(DATA_ROOT / 'outputs'),\n",
    "    'SAVE_ON_BEST': 'macro_f1',\n",
    "\n",
    "    # Inference aids\n",
    "    'ENABLE_SHEET_MASK': True,\n",
    "}\n",
    "\n",
    "print(CONFIG)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b48228b4",
   "metadata": {},
   "source": [
    "### Section 1a - Sync Data From Cloud Storage\n",
    "Connects to Google Cloud Storage, mirrors the `images/` hierarchy onto the notebook instance, and pulls down the label CSV/JSON artifacts. Existing local files are left untouched so repeated syncs are fast.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3662ca04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images already present locally.\n",
      "labels.csv already present locally.\n",
      "forsmith_roof_labels.json already present locally.\n",
      "[Taxonomy JSON check] forsmith_roof_labels.json: valid JSON (451763 bytes). First bytes: b'{\\r\\n  \"version\": 1,\\r\\n  \"source_sheets\": [\\r\\n    \"1.0 - B.U.R\",\\r\\n    \"2.0 - Mod. Bit.\",\\r\\n    \"3.0 - Thermoplastic\",\\r\\n    \"4.0 - IRM'\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# 1a) SYNC DATA FROM GCS\n",
    "# =========================\n",
    "from pathlib import Path\n",
    "from google.cloud import storage\n",
    "import json\n",
    "import io\n",
    "\n",
    "data_root = Path(CONFIG['DATA_ROOT'])\n",
    "data_root.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "images_dir = Path(CONFIG['IMAGES_DIR'])\n",
    "images_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "bucket_name = CONFIG.get('GCS_BUCKET')\n",
    "if not bucket_name:\n",
    "    print('No GCS bucket configured; skipping sync.')\n",
    "else:\n",
    "    try:\n",
    "        client = storage.Client()\n",
    "        bucket = client.bucket(bucket_name)\n",
    "    except Exception as exc:\n",
    "        raise RuntimeError(\n",
    "            'Failed to create a Cloud Storage client. Confirm your Vertex AI '\n",
    "            'Workbench environment has access to the project (service account/IAM).'\n",
    "        ) from exc\n",
    "\n",
    "    def _normalize(prefix: str) -> str:\n",
    "        if not prefix:\n",
    "            return ''\n",
    "        return prefix.strip('/') + '/'\n",
    "\n",
    "    def _strip_prefix(text: str, prefix: str) -> str:\n",
    "        if prefix and text.startswith(prefix):\n",
    "            return text[len(prefix):]\n",
    "        return text\n",
    "\n",
    "    images_prefix = _normalize(CONFIG.get('GCS_IMAGES_PREFIX', ''))\n",
    "    downloaded_images = 0\n",
    "    listed_any = False\n",
    "    for blob in client.list_blobs(bucket_name, prefix=images_prefix):\n",
    "        listed_any = True\n",
    "        if blob.name.endswith('/'):\n",
    "            continue\n",
    "        rel_path = _strip_prefix(blob.name, images_prefix).lstrip('/')\n",
    "        target = images_dir / rel_path\n",
    "        if target.exists():\n",
    "            continue\n",
    "        target.parent.mkdir(parents=True, exist_ok=True)\n",
    "        print(f'Downloading {blob.name} -> {target}')\n",
    "        blob.download_to_filename(target)\n",
    "        downloaded_images += 1\n",
    "    if not listed_any:\n",
    "        print(f'No objects found under gs://{bucket_name}/{images_prefix}')\n",
    "    elif downloaded_images == 0:\n",
    "        print('Images already present locally.')\n",
    "    else:\n",
    "        print(f'Downloaded {downloaded_images} new image files.')\n",
    "\n",
    "    def _download_file(gcs_key: str, local_key: str, force: bool = False):\n",
    "        remote_path = CONFIG.get(gcs_key)\n",
    "        if not remote_path:\n",
    "            return None\n",
    "        blob_name = remote_path.strip('/')\n",
    "        target_path = Path(CONFIG[local_key])\n",
    "        target_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        if force and target_path.exists():\n",
    "            print(f'Force re-sync on {target_path.name} … deleting local copy.')\n",
    "            try:\n",
    "                target_path.unlink()\n",
    "            except FileNotFoundError:\n",
    "                pass\n",
    "\n",
    "        if target_path.exists():\n",
    "            print(f'{target_path.name} already present locally.')\n",
    "            return target_path\n",
    "\n",
    "        print(f'Downloading gs://{bucket_name}/{blob_name} -> {target_path}')\n",
    "        blob = bucket.blob(blob_name)\n",
    "        if not blob.exists():\n",
    "            raise FileNotFoundError(\n",
    "                f'Blob gs://{bucket_name}/{blob_name} does not exist. '\n",
    "                'Check CONFIG paths.'\n",
    "            )\n",
    "        blob.download_to_filename(target_path)\n",
    "        return target_path\n",
    "\n",
    "    # CSV and JSON (taxonomy)\n",
    "    _download_file('GCS_LABELS_CSV', 'CSV_PATH')\n",
    "\n",
    "    # Allow forcing a clean pull of the JSON if it was previously corrupted/empty\n",
    "    FORCE_RESYNC_JSON = False  # set True if you keep hitting JSON issues\n",
    "\n",
    "    json_path = _download_file('GCS_LABELS_JSON', 'LABELS_JSON', force=FORCE_RESYNC_JSON)\n",
    "\n",
    "    # --- Sanity-check taxonomy JSON locally; if bad, auto re-download once ---\n",
    "    def _is_valid_json_file(p: Path) -> tuple[bool, str]:\n",
    "        if not p or not p.exists():\n",
    "            return False, 'file missing'\n",
    "        size = p.stat().st_size\n",
    "        if size == 0:\n",
    "            return False, 'file is empty (0 bytes)'\n",
    "        try:\n",
    "            with p.open('r', encoding='utf-8') as f:\n",
    "                json.load(f)\n",
    "            return True, f'valid JSON ({size} bytes)'\n",
    "        except Exception as e:\n",
    "            return False, f'json load failed: {type(e).__name__}: {e}'\n",
    "\n",
    "    if json_path and json_path.exists():\n",
    "        ok, msg = _is_valid_json_file(json_path)\n",
    "        # Print basic diagnostics to help you debug bucket contents vs local cache\n",
    "        head = Path(json_path).read_bytes()[:128]\n",
    "        print(f'[Taxonomy JSON check] {json_path.name}: {msg}. First bytes: {head!r}')\n",
    "        if not ok:\n",
    "            print('Attempting one forced re-sync of taxonomy JSON from GCS…')\n",
    "            json_path = _download_file('GCS_LABELS_JSON', 'LABELS_JSON', force=True)\n",
    "            ok2, msg2 = _is_valid_json_file(json_path)\n",
    "            print(f'[After re-sync] {json_path.name}: {msg2}')\n",
    "            if not ok2:\n",
    "                print('Warning: taxonomy JSON still invalid. Section 3 will try CSV/XLSX fallback.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb7fd8cd",
   "metadata": {},
   "source": [
    "### Section 2 - Import Libraries & Seed RNGs\n",
    "Adds the `_deps` directory to `sys.path`, imports PyTorch, Albumentations, scikit-learn, and helper utilities, and seeds Python/NumPy/Torch for reproducible runs while checking whether a GPU is available.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de6f1006",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# ================================\n",
    "# 2) ENVIRONMENT, INSTALLS, SEEDS\n",
    "# ================================\n",
    "# Dependencies installed above if needed.\n",
    "\n",
    "import os, json, math, random, time, shutil, pathlib\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "_DEPS_PATH = Path.cwd() / '_deps'\n",
    "if _DEPS_PATH.exists() and str(_DEPS_PATH) not in sys.path:\n",
    "    sys.path.insert(0, str(_DEPS_PATH))\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import timm\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "from sklearn.model_selection import GroupKFold, GroupShuffleSplit\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score\n",
    "\n",
    "# Determinism\n",
    "def set_seed(seed: int = 1337):\n",
    "    random.seed(seed); np.random.seed(seed); torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(CONFIG[\"SEED\"])\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1cf0742",
   "metadata": {},
   "source": [
    "### Section 3 - Load Taxonomy JSON\n",
    "Reads the taxonomy JSON, builds mappings between observation IDs and class indices, records sheet metadata, and prepares lookup tables that power masking and reporting later in the workflow.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc2e14ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Taxonomy] Source: json_ok\n",
      "[Taxonomy] Total classes: 424\n",
      "[Taxonomy] Example entries: [{'id': '1.01.01', 'label': 'Metal Edge Flashing', 'sheet': '1.0 - B.U.R', 'cause_effect': 'Improper installation, deterioration, external damage, etc. has caused the metal edge to not function as intended, which could lead to moisture ingress into the roof system and/or create a safety hazard.', 'recommendation': '', 'default_text': ''}, {'id': '1.01.02', 'label': 'Perimeter Membrane Flashings', 'sheet': '1.0 - B.U.R', 'cause_effect': 'Improper installation, deterioration, external damage, etc. could allow moisture migration to occur into the roof and/or wall assembly.', 'recommendation': '', 'default_text': ''}, {'id': '1.01.03', 'label': 'Perimeter Metal Flashings', 'sheet': '1.0 - B.U.R', 'cause_effect': 'Improper installation, deterioration, external damage, etc. has caused the metal flashings to not function as intended, which could lead to damage of the roof system and/or create a safety hazard.', 'recommendation': '', 'default_text': ''}]\n",
      "[Taxonomy] Sheets: ['1.0 - B.U.R', '2.0 - Mod. Bit.', '3.0 - Thermoplastic', '4.0 - IRMA', '5.0 - EPDM'] ...\n"
     ]
    }
   ],
   "source": [
    "# =========================================\n",
    "# 3) LOAD TAXONOMY & BUILD LABEL MAPS\n",
    "# =========================================\n",
    "import json\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "def _try_load_json(path: Path):\n",
    "    \"\"\"Strict JSON loader, then a BOM/lenient pass, else None.\"\"\"\n",
    "    if not path or not path.exists():\n",
    "        return None, 'missing'\n",
    "    try:\n",
    "        with path.open('r', encoding='utf-8') as f:\n",
    "            return json.load(f), 'json_ok'\n",
    "    except Exception as e1:\n",
    "        # try UTF-8-SIG (handles BOM) and a small repair pass\n",
    "        try:\n",
    "            raw = path.read_text(encoding='utf-8-sig')\n",
    "            # minimal repair: sometimes people save with single quotes or trailing commas\n",
    "            repaired = raw.replace(\"'\", '\"')  # safest minimal tweak\n",
    "            return json.loads(repaired), f'json_repaired ({type(e1).__name__})'\n",
    "        except Exception as e2:\n",
    "            return None, f'json_failed ({type(e1).__name__} -> {type(e2).__name__})'\n",
    "\n",
    "def _try_load_csv(path: Path):\n",
    "    \"\"\"Load CSV schema: expects at least observation_id, label, sheet.\"\"\"\n",
    "    if not path or not path.exists():\n",
    "        return None, 'missing'\n",
    "    try:\n",
    "        df = pd.read_csv(path)\n",
    "        return df, 'csv_ok'\n",
    "    except Exception as e:\n",
    "        return None, f'csv_failed ({type(e).__name__})'\n",
    "\n",
    "def _try_load_xlsx(path: Path):\n",
    "    \"\"\"If your taxonomy lives in an .xlsx instead, try to parse it here.\"\"\"\n",
    "    if not path or not path.exists():\n",
    "        return None, 'missing'\n",
    "    try:\n",
    "        df = pd.read_excel(path)\n",
    "        return df, 'xlsx_ok'\n",
    "    except Exception as e:\n",
    "        return None, f'xlsx_failed ({type(e).__name__})'\n",
    "\n",
    "def _normalize_records_from_df(df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Normalize a dataframe with columns like:\n",
    "      observation_id / id, label, sheet, cause_effect, recommendation, default_text, etc.\n",
    "    Only id/label/sheet are required for the classifier mapping; others are optional.\n",
    "    \"\"\"\n",
    "    # Flexible column mapping\n",
    "    colmap = {\n",
    "        'id': None,\n",
    "        'observation_id': None,\n",
    "        'label': None,\n",
    "        'sheet': None,\n",
    "        'cause_effect': None,\n",
    "        'recommendation': None,\n",
    "        'default_text': None,\n",
    "    }\n",
    "    lower_cols = {c.lower(): c for c in df.columns}\n",
    "\n",
    "    def pick(*names):\n",
    "        for n in names:\n",
    "            if n in lower_cols:\n",
    "                return lower_cols[n]\n",
    "        return None\n",
    "\n",
    "    colmap['id'] = pick('id', 'observation_id', 'obs_id')\n",
    "    colmap['observation_id'] = colmap['id']  # treat as same\n",
    "    colmap['label'] = pick('label', 'name', 'class')\n",
    "    colmap['sheet'] = pick('sheet', 'category', 'group')\n",
    "    colmap['cause_effect'] = pick('cause_effect', 'cause/effect', 'cause')\n",
    "    colmap['recommendation'] = pick('recommendation', 'recommendations')\n",
    "    colmap['default_text'] = pick('default_text', 'text', 'boilerplate')\n",
    "\n",
    "    required = [colmap['id'], colmap['label'], colmap['sheet']]\n",
    "    if any(c is None for c in required):\n",
    "        missing = [k for k, v in {'id': colmap['id'], 'label': colmap['label'], 'sheet': colmap['sheet']}.items() if v is None]\n",
    "        raise ValueError(f'Missing required columns in taxonomy table: {missing}. '\n",
    "                         f'Found columns: {list(df.columns)}')\n",
    "\n",
    "    recs = []\n",
    "    for _, row in df.iterrows():\n",
    "        recs.append({\n",
    "            'id': str(row[colmap['id']]).strip(),\n",
    "            'label': str(row[colmap['label']]).strip(),\n",
    "            'sheet': str(row[colmap['sheet']]).strip(),\n",
    "            'cause_effect': (str(row[colmap['cause_effect']]).strip()\n",
    "                             if colmap['cause_effect'] else ''),\n",
    "            'recommendation': (str(row[colmap['recommendation']]).strip()\n",
    "                               if colmap['recommendation'] else ''),\n",
    "            'default_text': (str(row[colmap['default_text']]).strip()\n",
    "                             if colmap['default_text'] else ''),\n",
    "        })\n",
    "    return recs\n",
    "\n",
    "# --- Load order: JSON → CSV → XLSX ---\n",
    "labels_json_path = Path(CONFIG[\"LABELS_JSON\"])\n",
    "labels_csv_path  = Path(CONFIG[\"CSV_PATH\"])\n",
    "\n",
    "labels_raw, src = _try_load_json(labels_json_path)\n",
    "if labels_raw is None:\n",
    "    print(f'[Taxonomy] JSON load failed: {src}. Trying CSV fallback…')\n",
    "    df_csv, src_csv = _try_load_csv(labels_csv_path)\n",
    "    if df_csv is not None:\n",
    "        labels_raw = _normalize_records_from_df(df_csv)\n",
    "        src = f'csv_fallback ({src_csv})'\n",
    "    else:\n",
    "        # Optional XLSX fallback if you keep a spreadsheet version\n",
    "        # Put its local path in CONFIG like CONFIG[\"LABELS_XLSX\"] if you want this path to be dynamic\n",
    "        xlsx_path = Path(CONFIG.get('LABELS_XLSX', ''))\n",
    "        df_xlsx, src_xlsx = _try_load_xlsx(xlsx_path) if xlsx_path else (None, 'missing')\n",
    "        if df_xlsx is not None:\n",
    "            labels_raw = _normalize_records_from_df(df_xlsx)\n",
    "            src = f'xlsx_fallback ({src_xlsx})'\n",
    "        else:\n",
    "            raise RuntimeError(\n",
    "                f'Could not load taxonomy from JSON ({src}), CSV ({src_csv}), '\n",
    "                f'or XLSX ({src_xlsx}). Fix your artifacts and rerun.'\n",
    "            )\n",
    "\n",
    "# Validate shape and normalize minimal fields\n",
    "if isinstance(labels_raw, dict):\n",
    "    # Some exports store items under a key like \"items\"\n",
    "    labels_raw = labels_raw.get('items', [])\n",
    "if not isinstance(labels_raw, list):\n",
    "    raise TypeError(f'Expected taxonomy to be a list; got {type(labels_raw)}')\n",
    "\n",
    "def _coerce_record(it):\n",
    "    return {\n",
    "        'id': str(it.get('id') or it.get('observation_id') or '').strip(),\n",
    "        'label': str(it.get('label') or '').strip(),\n",
    "        'sheet': str(it.get('sheet') or '').strip(),\n",
    "        'cause_effect': str(it.get('cause_effect') or ''),\n",
    "        'recommendation': str(it.get('recommendation') or ''),\n",
    "        'default_text': str(it.get('default_text') or ''),\n",
    "    }\n",
    "\n",
    "labels_norm = [_coerce_record(it) for it in labels_raw if (it.get('id') or it.get('observation_id')) and it.get('label')]\n",
    "if not labels_norm:\n",
    "    raise ValueError('Taxonomy normalization produced 0 items—check your JSON/CSV/XLSX content.')\n",
    "\n",
    "# Build maps\n",
    "obs_ids = [it[\"id\"] for it in labels_norm]\n",
    "id_to_idx = {oid: i for i, oid in enumerate(obs_ids)}\n",
    "idx_to_info = {\n",
    "    i: {\n",
    "        \"observation_id\": it[\"id\"],\n",
    "        \"label\": it[\"label\"],\n",
    "        \"sheet\": it[\"sheet\"],\n",
    "        \"cause_effect\": it.get(\"cause_effect\", \"\"),\n",
    "        \"recommendation\": it.get(\"recommendation\", \"\"),\n",
    "        \"default_text\": it.get(\"default_text\", \"\"),\n",
    "    }\n",
    "    for i, it in enumerate(labels_norm)\n",
    "}\n",
    "\n",
    "# Sheet → set of obs_ids (for inference masking)\n",
    "sheet_to_ids = {}\n",
    "for it in labels_norm:\n",
    "    sheet_to_ids.setdefault(it[\"sheet\"], set()).add(it[\"id\"])\n",
    "\n",
    "print(f\"[Taxonomy] Source: {src}\")\n",
    "print(f\"[Taxonomy] Total classes: {len(obs_ids)}\")\n",
    "print(\"[Taxonomy] Example entries:\", labels_norm[:3])\n",
    "print(\"[Taxonomy] Sheets:\", list(sheet_to_ids.keys())[:5], \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c3d9e1",
   "metadata": {},
   "source": [
    "### Section 4 - Load Dataset Manifest\n",
    "Ingests the labels CSV, verifies schema, derives a `report_id` grouping from each filename, filters to taxonomy-supported observations, and attaches numeric class indices required for model training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eac6ee2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  image_file                                   label  \\\n",
      "0  18-053-12_page12_img2.png                    Unprotected Openings   \n",
      "1  18-053-12_page17_img3.png             Redundant roof penetrations   \n",
      "2   23-023R1_page20_img2.png                     Subsurface Moisture   \n",
      "3    23-023R1_page5_img3.png  Conduit Penetration Through Mech. Unit   \n",
      "4     21-009_page18_img2.png  Conduit Penetration Through Mech. Unit   \n",
      "\n",
      "  observation_id  confidence  report_id  class_index  \n",
      "0        2.11.02       0.502  18-053-12          130  \n",
      "1        2.06.01       0.504  18-053-12           96  \n",
      "2        2.12.01       0.505   23-023R1          132  \n",
      "3        2.04.04       0.506   23-023R1           88  \n",
      "4        2.04.04       0.506     21-009           88  \n",
      "Unique reports: 106  | images: 1616  | classes in use: 121\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# =====================================================\n",
    "# 4) LOAD DATASET CSV & EXTRACT report_id FROM FILENAME\n",
    "# =====================================================\n",
    "df = pd.read_csv(CONFIG[\"CSV_PATH\"])\n",
    "expected_cols = {\"image_file\",\"label\",\"observation_id\"}\n",
    "missing = expected_cols - set(df.columns)\n",
    "assert not missing, f\"CSV missing columns: {missing}\"\n",
    "\n",
    "# Derive report_id: everything before '_page'\n",
    "def get_report_id(fname: str) -> str:\n",
    "    base = Path(fname).stem\n",
    "    # e.g., '20-063_page41_img2' -> '20-063'\n",
    "    return base.split(\"_page\")[0]\n",
    "\n",
    "df[\"report_id\"] = df[\"image_file\"].map(get_report_id)\n",
    "\n",
    "# Filter to only obs_ids present in JSON (defensive)\n",
    "df = df[df[\"observation_id\"].isin(id_to_idx.keys())].copy()\n",
    "df[\"class_index\"] = df[\"observation_id\"].map(id_to_idx)\n",
    "print(df.head())\n",
    "print(\"Unique reports:\", df[\"report_id\"].nunique(), \" | images:\", len(df), \" | classes in use:\", df[\"class_index\"].nunique())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab577950",
   "metadata": {},
   "source": [
    "### Section 5 - Create Group-Aware Splits\n",
    "Uses group-based splitters to hold out a test set and generate cross-validation folds without leaking report-level context between train, validation, and test partitions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "18b4ccfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train+Val: 1231  | Test: 385\n",
      "Fold 0: train=984, val=247\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ==================================================\n",
    "# 5) GROUP-AWARE SPLITS (TEST; then CV folds for TR/VAL)\n",
    "# ==================================================\n",
    "gss = GroupShuffleSplit(n_splits=1, test_size=CONFIG[\"TEST_SIZE\"], random_state=CONFIG[\"SEED\"])\n",
    "trainval_idx, test_idx = next(gss.split(df, groups=df[\"report_id\"]))\n",
    "df_trainval = df.iloc[trainval_idx].reset_index(drop=True)\n",
    "df_test = df.iloc[test_idx].reset_index(drop=True)\n",
    "\n",
    "print(\"Train+Val:\", len(df_trainval), \" | Test:\", len(df_test))\n",
    "\n",
    "gkf = GroupKFold(n_splits=CONFIG[\"N_SPLITS\"])\n",
    "folds = list(gkf.split(df_trainval, df_trainval[\"class_index\"], groups=df_trainval[\"report_id\"]))\n",
    "train_idx, val_idx = folds[CONFIG[\"FOLD_INDEX\"]]\n",
    "\n",
    "train_df = df_trainval.iloc[train_idx].reset_index(drop=True)\n",
    "val_df = df_trainval.iloc[val_idx].reset_index(drop=True)\n",
    "\n",
    "print(f\"Fold {CONFIG['FOLD_INDEX']}: train={len(train_df)}, val={len(val_df)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b9230da",
   "metadata": {},
   "source": [
    "### Section 6 - Compute Class Weights\n",
    "Calculates inverse-frequency weights from the training data so the loss emphasises under-represented classes during optimisation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3ce2f396-7c6a-41dc-9aed-ed553fb6aacf",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_dataset_raw' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 42\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m labels\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# ---------- Build mapping for active classes ----------\u001b[39;00m\n\u001b[0;32m---> 42\u001b[0m train_labels_raw \u001b[38;5;241m=\u001b[39m _get_labels(\u001b[43mtrain_dataset_raw\u001b[49m)\n\u001b[1;32m     43\u001b[0m val_labels_raw   \u001b[38;5;241m=\u001b[39m _get_labels(val_dataset_raw)\n\u001b[1;32m     45\u001b[0m active_old_ids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(\u001b[38;5;28mset\u001b[39m(train_labels_raw) \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mset\u001b[39m(val_labels_raw))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_dataset_raw' is not defined"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# Section 6a – Active Class Discovery & Remap (FINAL)\n",
    "# ============================\n",
    "import torch, numpy as np\n",
    "from torch.utils.data import Subset, Dataset\n",
    "\n",
    "# ---------- Helper: safely extract labels ----------\n",
    "def _get_labels(dset):\n",
    "    \"\"\"Return list[int] of labels without heavy transform calls.\"\"\"\n",
    "    # Common attributes first\n",
    "    if hasattr(dset, \"targets\") and len(getattr(dset, \"targets\")) == len(dset):\n",
    "        return [int(t) for t in dset.targets]\n",
    "    if hasattr(dset, \"labels\") and len(getattr(dset, \"labels\")) == len(dset):\n",
    "        return [int(t) for t in dset.labels]\n",
    "    for name in (\"samples\", \"imgs\"):\n",
    "        if hasattr(dset, name):\n",
    "            items = getattr(dset, name)\n",
    "            try:\n",
    "                return [int(lbl) for _, lbl in items]\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "    # Fallback: light index read\n",
    "    labels = []\n",
    "    for i in range(len(dset)):\n",
    "        it = dset[i]\n",
    "        if isinstance(it, tuple) and len(it) >= 2:\n",
    "            labels.append(int(it[1]))\n",
    "        elif isinstance(it, dict):\n",
    "            for k in (\"label\", \"target\", \"y\"):\n",
    "                if k in it:\n",
    "                    val = it[k]\n",
    "                    if isinstance(val, (list, tuple)): val = val[0]\n",
    "                    labels.append(int(val))\n",
    "                    break\n",
    "        else:\n",
    "            raise TypeError(f\"Unsupported item type {type(it)} at index {i}\")\n",
    "    return labels\n",
    "\n",
    "\n",
    "# ---------- Build mapping for active classes ----------\n",
    "train_labels_raw = _get_labels(train_dataset_raw)\n",
    "val_labels_raw   = _get_labels(val_dataset_raw)\n",
    "\n",
    "active_old_ids = sorted(set(train_labels_raw) | set(val_labels_raw))\n",
    "old2new = {old: i for i, old in enumerate(active_old_ids)}\n",
    "new2old = {i: old for old, i in old2new.items()}\n",
    "K = len(active_old_ids)\n",
    "print(f\"[6a] Active classes in this run: {K} / 424\")\n",
    "\n",
    "\n",
    "# ---------- Dataset wrapper to remap labels ----------\n",
    "class _Remap(Dataset):\n",
    "    def __init__(self, base, id_map):\n",
    "        self.base, self.id_map = base, id_map\n",
    "    def __len__(self): return len(self.base)\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.base[idx]\n",
    "        # Handle tuple (x,y)\n",
    "        if isinstance(item, tuple) and len(item) >= 2:\n",
    "            x, y_old = item[0], int(item[1])\n",
    "            return x, self.id_map[y_old]\n",
    "        # Handle dict-like item\n",
    "        if isinstance(item, dict):\n",
    "            out = dict(item)\n",
    "            y_old = None\n",
    "            for k in (\"label\", \"target\", \"y\"):\n",
    "                if k in out:\n",
    "                    val = out[k]\n",
    "                    if isinstance(val, (list, tuple)): val = val[0]\n",
    "                    y_old = int(val)\n",
    "                    out[k] = self.id_map[y_old]\n",
    "                    break\n",
    "            if y_old is None:\n",
    "                raise ValueError(\"Dict item missing label/target/y key.\")\n",
    "            return out\n",
    "        raise TypeError(f\"Unsupported dataset item type: {type(item)}\")\n",
    "\n",
    "\n",
    "# ---------- Filter to active classes (no transform calls) ----------\n",
    "train_kept = [i for i, y in enumerate(train_labels_raw) if int(y) in old2new]\n",
    "val_kept   = [i for i, y in enumerate(val_labels_raw)   if int(y) in old2new]\n",
    "\n",
    "train_dataset = _Remap(Subset(train_dataset_raw, train_kept), old2new)\n",
    "val_dataset   = _Remap(Subset(val_dataset_raw,   val_kept),   old2new)\n",
    "\n",
    "\n",
    "# ---------- Compute class weights ----------\n",
    "train_labels_new = np.array([\n",
    "    int(train_dataset[i][1]) if isinstance(train_dataset[i], tuple)\n",
    "    else int(next(v for k,v in train_dataset[i].items() if k in (\"label\",\"target\",\"y\")))\n",
    "    for i in range(len(train_dataset))\n",
    "])\n",
    "counts = np.bincount(train_labels_new, minlength=K)\n",
    "class_weights = 1.0 / np.clip(counts, 1, None)\n",
    "\n",
    "print(f\"[6a] After remap → K={K} | train={len(train_dataset)} | val={len(val_dataset)}\")\n",
    "print(f\"[6a] Non-empty train classes: {(counts>0).sum()} / {K}\")\n",
    "\n",
    "# Optional quick probe\n",
    "sample = train_dataset[0]\n",
    "if isinstance(sample, tuple):\n",
    "    x, y = sample\n",
    "    print(f\"[6a] Example tuple item → label={y}, type(x)={type(x)}, shape={getattr(x, 'shape', None)}\")\n",
    "else:\n",
    "    print(f\"[6a] Example dict item keys → {list(sample.keys())}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2cb4854",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ===========================================\n",
    "# 6) CLASS WEIGHTS (inverse frequency simple)\n",
    "# ===========================================\n",
    "class_counts = train_df[\"class_index\"].value_counts().sort_index()\n",
    "num_classes = len(obs_ids)\n",
    "freq = np.ones(num_classes)\n",
    "freq[class_counts.index.values] = class_counts.values\n",
    "inv_freq = 1.0 / np.clip(freq, 1.0, None)\n",
    "class_weights = inv_freq / inv_freq.sum() * num_classes\n",
    "class_weights = torch.tensor(class_weights, dtype=torch.float32).to(device)\n",
    "print(\"Example weights (first 10):\", class_weights[:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6336fba5",
   "metadata": {},
   "source": [
    "### Section 7 - Define Image Transforms\n",
    "Configures Albumentations pipelines for training, validation, and inference: resizing, normalization, and light augmentations matched to the configured input size.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdef798b-ac21-4ea8-a453-ebf92e242511",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================\n",
    "# 7) IMAGE TRANSFORMS (Albumentations)\n",
    "# =====================================\n",
    "import cv2\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "IMG = CONFIG[\"IMAGE_SIZE\"]\n",
    "PAD_COLOR = (128, 128, 128)\n",
    "\n",
    "# ---- Helpers with conservative, cross-version-safe kwargs -------------------\n",
    "def _pad_kwargs():\n",
    "    # Use 'value' universally to satisfy 1.x; harmless in 2.x when accepted via SSR.\n",
    "    return dict(border_mode=cv2.BORDER_CONSTANT, value=PAD_COLOR)\n",
    "\n",
    "def _image_compression_kwargs():\n",
    "    # Prefer 2.x API, fallback to 1.x gracefully.\n",
    "    try:\n",
    "        _ = A.ImageCompression(quality_range=(80, 100), p=0.0)\n",
    "        return dict(quality_range=(80, 100))\n",
    "    except TypeError:\n",
    "        return dict(quality_lower=80, quality_upper=100)\n",
    "\n",
    "def _random_resized_crop(height, width, **common):\n",
    "    # Some builds want size=(H,W); others height=..., width=...\n",
    "    try:\n",
    "        return A.RandomResizedCrop(size=(height, width), **common)\n",
    "    except TypeError:\n",
    "        return A.RandomResizedCrop(height=height, width=width, **common)\n",
    "\n",
    "def _mild_geo():\n",
    "    \"\"\"\n",
    "    Prefer ShiftScaleRotate across versions (translation via shift_limit,\n",
    "    small scale/rotate). If SSR isn't present, fall back to Affine WITHOUT\n",
    "    mode/cval (keeps signature-compatible).\n",
    "    \"\"\"\n",
    "    if hasattr(A, \"ShiftScaleRotate\"):\n",
    "        return A.ShiftScaleRotate(\n",
    "            shift_limit=0.02,     # ~±2% translation\n",
    "            scale_limit=0.05,     # ~±5% scale\n",
    "            rotate_limit=5,       # ±5 degrees\n",
    "            border_mode=cv2.BORDER_CONSTANT,\n",
    "            value=PAD_COLOR,      # universal kw for fill\n",
    "            p=0.5,\n",
    "        )\n",
    "    else:\n",
    "        # Minimal-arg Affine that avoids 'mode'/'cval' complaints\n",
    "        return A.Affine(\n",
    "            translate_percent={\"x\": (-0.02, 0.02), \"y\": (-0.02, 0.02)},\n",
    "            scale=(0.95, 1.05),\n",
    "            rotate=(-5, 5),\n",
    "            p=0.5,\n",
    "        )\n",
    "\n",
    "# ---- Pipelines --------------------------------------------------------------\n",
    "train_tfms = A.Compose([\n",
    "    A.LongestMaxSize(max_size=IMG, interpolation=cv2.INTER_AREA),\n",
    "\n",
    "    A.PadIfNeeded(min_height=IMG, min_width=IMG, **_pad_kwargs()),\n",
    "\n",
    "    _random_resized_crop(\n",
    "        IMG, IMG, scale=(0.90, 1.0), ratio=(0.9, 1.1), p=0.7\n",
    "    ),\n",
    "\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "\n",
    "    _mild_geo(),\n",
    "\n",
    "    A.RandomBrightnessContrast(p=0.5),\n",
    "\n",
    "    A.ImageCompression(p=0.3, **_image_compression_kwargs()),\n",
    "\n",
    "    A.Normalize(mean=(0.5, 0.5, 0.5), std=(0.25, 0.25, 0.25)),\n",
    "    ToTensorV2(),\n",
    "])\n",
    "\n",
    "eval_tfms = A.Compose([\n",
    "    A.LongestMaxSize(max_size=IMG, interpolation=cv2.INTER_AREA),\n",
    "    A.PadIfNeeded(min_height=IMG, min_width=IMG, **_pad_kwargs()),\n",
    "    A.Normalize(mean=(0.5, 0.5, 0.5), std=(0.25, 0.25, 0.25)),\n",
    "    ToTensorV2(),\n",
    "])\n",
    "\n",
    "# ---- quick probe ------------------------------------------------------------\n",
    "if True:\n",
    "    import numpy as _np\n",
    "    _fake = (_np.random.rand(320, 500, 3) * 255).astype(\"uint8\")\n",
    "    _out = train_tfms(image=_fake)[\"image\"]; assert _out.shape[-2:] == (IMG, IMG)\n",
    "    _out2 = eval_tfms(image=_fake)[\"image\"];  assert _out2.shape[-2:] == (IMG, IMG)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e65133-eabf-4af8-8068-b7248b3579f1",
   "metadata": {},
   "source": [
    "Sanity Probe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a327ea-518f-42bd-9ceb-f78c732ef820",
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as _A, numpy as _np, cv2 as _cv2\n",
    "print(\"Albumentations:\", _A.__version__)\n",
    "\n",
    "# Make a fake RGB uint8 image with non-square shape to exercise pad/crop\n",
    "_fake = (_np.random.rand(320, 500, 3) * 255).astype(\"uint8\")\n",
    "try:\n",
    "    _out = train_tfms(image=_fake)[\"image\"]  # torch.Tensor CxHxW\n",
    "    print(\"train_tfms ok:\", tuple(_out.shape))\n",
    "    assert _out.shape[-2:] == (IMG, IMG), \"train_tfms must output IMGxIMG\"\n",
    "except Exception as e:\n",
    "    print(\"train_tfms FAILED:\", repr(e))\n",
    "    raise\n",
    "\n",
    "try:\n",
    "    _out2 = eval_tfms(image=_fake)[\"image\"]\n",
    "    print(\"eval_tfms ok:\", tuple(_out2.shape))\n",
    "    assert _out2.shape[-2:] == (IMG, IMG), \"eval_tfms must output IMGxIMG\"\n",
    "except Exception as e:\n",
    "    print(\"eval_tfms FAILED:\", repr(e))\n",
    "    raise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17920d8f",
   "metadata": {},
   "source": [
    "### Section 8 - Dataset & DataLoaders\n",
    "Implements the PyTorch dataset wrapper that reads images, applies transforms, and returns tensors plus class indices. Also instantiates the train/validation/test `DataLoader` objects with appropriate batching options.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd38931",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Section 8 - Dataset & DataLoaders\n",
    "# =========================\n",
    "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
    "import numpy as np\n",
    "\n",
    "BATCH_SIZE = CONFIG.get(\"BATCH_SIZE\", 32)\n",
    "\n",
    "# Balanced sampling to help tiny/imbalanced data\n",
    "train_labels_new = np.array([int(train_dataset[i][1]) for i in range(len(train_dataset))])\n",
    "counts = np.bincount(train_labels_new, minlength=len(class_weights))\n",
    "class_weights = 1.0 / np.clip(counts, 1, None)  # ensure synced with Section 6a\n",
    "sample_weights = class_weights[train_labels_new]\n",
    "sampler = WeightedRandomSampler(sample_weights.tolist(), len(sample_weights), replacement=True)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, batch_size=BATCH_SIZE, sampler=sampler,\n",
    "    num_workers=CONFIG.get(\"NUM_WORKERS\", 4), pin_memory=True\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_dataset, batch_size=BATCH_SIZE, shuffle=False,\n",
    "    num_workers=CONFIG.get(\"NUM_WORKERS\", 4), pin_memory=True\n",
    ")\n",
    "\n",
    "# Cross-entropy with class weights + light label smoothing\n",
    "crit = torch.nn.CrossEntropyLoss(\n",
    "    weight=torch.tensor(class_weights, dtype=torch.float32, device=device),\n",
    "    label_smoothing=0.10\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b09028dd",
   "metadata": {},
   "source": [
    "### Section 9 - Build DINOv2 Model\n",
    "Instantiates the timm DINOv2 ViT-S/14 backbone, swaps in a classifier sized for the dataset, and prepares the network for staged fine-tuning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47018729",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================\n",
    "# Section 9 – Build DINOv2 Model\n",
    "# =========================================\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "assert K > 0, \"Active-class K not set. Run Section 6a before this.\"\n",
    "\n",
    "# --- Load / create your DINOv2 backbone here ---\n",
    "# If you already created `model` earlier, keep it. Otherwise, an example:\n",
    "try:\n",
    "    _ = model  # keep existing model if present\n",
    "except NameError:\n",
    "    from torchvision.models.vision_transformer import vit_b_16  # placeholder if you need a stub\n",
    "    model = vit_b_16(weights=None)  # replace with your DINOv2 backbone load\n",
    "\n",
    "# Ensure we have a \"backbone\" attribute or an equivalent forward_features:\n",
    "if not hasattr(model, \"backbone\"):\n",
    "    # Try to create a lightweight wrapper so we can freeze a backbone and attach a head\n",
    "    class Wrap(torch.nn.Module):\n",
    "        def __init__(self, base):\n",
    "            super().__init__()\n",
    "            self.backbone = base\n",
    "            # temporary dummy head; will be replaced\n",
    "            self.head = nn.Identity()\n",
    "        def forward_features(self, x):\n",
    "            # Try dino-like API; else fall back to forward\n",
    "            if hasattr(self.backbone, \"forward_features\"):\n",
    "                return self.backbone.forward_features(x)\n",
    "            return self.backbone(x)\n",
    "        def forward(self, x):\n",
    "            feats = self.forward_features(x)\n",
    "            if isinstance(feats, (list, tuple)):\n",
    "                feats = feats[0]\n",
    "            # If backbone already outputs logits, stop earlier; here we force a linear head usage\n",
    "            if feats.ndim > 2:\n",
    "                feats = feats.mean(dim=(-2, -1))  # global pool if needed\n",
    "            return self.head(feats)\n",
    "\n",
    "    model = Wrap(model)\n",
    "\n",
    "# Freeze backbone for linear probe\n",
    "for p in model.backbone.parameters():\n",
    "    p.requires_grad = False\n",
    "\n",
    "# Infer feature dim for the head\n",
    "model = model.to(device).eval()\n",
    "with torch.no_grad():\n",
    "    dummy = torch.randn(1, 3, IMG, IMG, device=device)\n",
    "    if hasattr(model, \"forward_features\"):\n",
    "        feats = model.forward_features(dummy)\n",
    "    else:\n",
    "        feats = model.backbone(dummy)\n",
    "    if isinstance(feats, (list, tuple)):\n",
    "        feats = feats[0]\n",
    "    if feats.ndim > 2:  # e.g., feature map\n",
    "        feats = feats.mean(dim=(-2, -1))\n",
    "    feat_dim = feats.shape[-1]\n",
    "\n",
    "# Replace head to match only active classes K\n",
    "model.head = nn.Linear(feat_dim, K).to(device)\n",
    "print(f\"[Section 9] Linear head -> in_features={feat_dim}, out_features={K}\")\n",
    "model.train()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0601dbf",
   "metadata": {},
   "source": [
    "### Section 10 - Optimiser Helpers\n",
    "Provides utility functions to construct the AdamW optimiser and cosine learning-rate scheduler with warm-up so each training phase can initialise its own optimiser stack consistently.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e55d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================\n",
    "# Section 10 – Optimiser & Scheduler \n",
    "# ==============================================\n",
    "import torch.optim as optim\n",
    "\n",
    "HEAD_LR = CONFIG.get(\"HEAD_LR\", 5e-2)   # punchy LR for linear probe\n",
    "WD      = CONFIG.get(\"WEIGHT_DECAY\", 1e-4)\n",
    "EPOCHS  = CONFIG.get(\"EPOCHS\", 20)\n",
    "\n",
    "optimizer = optim.SGD(model.head.parameters(), lr=HEAD_LR, momentum=0.9, weight_decay=WD)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS)\n",
    "\n",
    "print(f\"[Section 10] Optimizer=SGD(lr={HEAD_LR}, wd={WD}), Scheduler=Cosine(T_max={EPOCHS})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdecd81f-ac94-42fc-9524-b3a91c05d3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================\n",
    "# 10.1) CHECKPOINT & RESUME\n",
    "# ===========================\n",
    "import json, time\n",
    "\n",
    "CKPT_DIR = CONFIG[\"OUT_DIR\"]\n",
    "CKPT_LAST = os.path.join(CKPT_DIR, \"last.pt\")\n",
    "CKPT_BEST = os.path.join(CKPT_DIR, \"best.pt\")\n",
    "CKPT_META = os.path.join(CKPT_DIR, \"meta.json\")\n",
    "\n",
    "def save_ckpt(state_dict, optimizer, epoch, phase, best_f1=None, is_best=False):\n",
    "    os.makedirs(CKPT_DIR, exist_ok=True)\n",
    "    payload = {\n",
    "        \"model\": state_dict,\n",
    "        \"optimizer\": optimizer.state_dict() if optimizer else None,\n",
    "        \"epoch\": epoch,\n",
    "        \"phase\": phase,\n",
    "        \"best_f1\": best_f1,\n",
    "        \"ts\": time.time(),\n",
    "        \"config\": CONFIG,\n",
    "    }\n",
    "    torch.save(payload, CKPT_LAST)\n",
    "    if is_best:\n",
    "        torch.save(payload, CKPT_BEST)\n",
    "    with open(CKPT_META, \"w\") as f:\n",
    "        json.dump({k:v for k,v in payload.items() if k not in (\"model\",\"optimizer\")}, f, indent=2)\n",
    "    print(f\"[CKPT] Saved {'BEST' if is_best else 'LAST'} at epoch {epoch} ({phase})\")\n",
    "\n",
    "def try_resume(net, optimizer=None, path=None):\n",
    "    path = path or (CONFIG.get(\"RESUME_FROM\") or CKPT_LAST)\n",
    "    if not os.path.exists(path):\n",
    "        print(\"[CKPT] No resume checkpoint found.\")\n",
    "        return 0, None, None\n",
    "    ckpt = torch.load(path, map_location=\"cpu\")\n",
    "    net.load_state_dict(ckpt[\"model\"], strict=True)\n",
    "    if optimizer is not None and ckpt.get(\"optimizer\"):\n",
    "        optimizer.load_state_dict(ckpt[\"optimizer\"])\n",
    "    print(f\"[CKPT] Resumed from {path} at epoch {ckpt['epoch']} (phase={ckpt['phase']}) best_f1={ckpt.get('best_f1')}\")\n",
    "    return ckpt[\"epoch\"], ckpt.get(\"phase\"), ckpt.get(\"best_f1\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb57fcf",
   "metadata": {},
   "source": [
    "### Section 11 - Training & Evaluation Loops\n",
    "Implements the shared training loop, validation pass, and three-phase schedule (linear probe, partial unfreeze, full fine-tune) while tracking metrics with torchmetrics and supporting mixed precision.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f227da91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Section 11 – Training & Evaluation Loops (REPLACED)\n",
    "# ====================================================\n",
    "import contextlib\n",
    "from torch import amp\n",
    "from tqdm import tqdm\n",
    "\n",
    "USE_AMP   = CONFIG.get(\"USE_AMP\", True)\n",
    "AMP_DTYPE = torch.float16  # switch to torch.bfloat16 if your GPU supports it better\n",
    "scaler = amp.GradScaler('cuda') if USE_AMP else None\n",
    "\n",
    "def _forward(x, y):\n",
    "    ctx = amp.autocast('cuda', dtype=AMP_DTYPE) if USE_AMP else contextlib.nullcontext()\n",
    "    with ctx:\n",
    "        logits = model(x)\n",
    "        loss   = crit(logits, y)\n",
    "    return logits, loss\n",
    "\n",
    "def train_one_epoch(epoch, loader):\n",
    "    model.train()\n",
    "    running_loss, running_correct, seen = 0.0, 0, 0\n",
    "    pbar = tqdm(loader, desc=f\"[Train] Epoch {epoch}\", leave=False)\n",
    "    for x, y in pbar:\n",
    "        x, y = x.to(device, non_blocking=True), y.to(device, non_blocking=True)\n",
    "\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        logits, loss = _forward(x, y)\n",
    "        if USE_AMP:\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "        else:\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        preds = logits.argmax(1)\n",
    "        running_correct += (preds == y).sum().item()\n",
    "        seen += y.size(0)\n",
    "        running_loss += loss.item() * y.size(0)\n",
    "        pbar.set_postfix(loss=running_loss/seen, acc=running_correct/seen)\n",
    "\n",
    "    scheduler.step()\n",
    "    return running_loss/seen, running_correct/seen\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(epoch, loader):\n",
    "    model.eval()\n",
    "    total_loss, total_correct, seen = 0.0, 0, 0\n",
    "    for x, y in loader:\n",
    "        x, y = x.to(device, non_blocking=True), y.to(device, non_blocking=True)\n",
    "        logits, loss = _forward(x, y)\n",
    "        preds = logits.argmax(1)\n",
    "        total_loss   += loss.item() * y.size(0)\n",
    "        total_correct += (preds == y).sum().item()\n",
    "        seen += y.size(0)\n",
    "    return total_loss/seen, total_correct/seen\n",
    "\n",
    "def fit(epochs=EPOCHS):\n",
    "    best_val = -1.0\n",
    "    for ep in range(1, epochs+1):\n",
    "        tr_loss, tr_acc = train_one_epoch(ep, train_loader)\n",
    "        va_loss, va_acc = evaluate(ep, val_loader)\n",
    "        print(f\"[Epoch {ep:02d}] train: loss {tr_loss:.4f} acc {tr_acc:.4f} | val: loss {va_loss:.4f} acc {va_acc:.4f}\")\n",
    "        if va_acc > best_val:\n",
    "            best_val = va_acc\n",
    "            torch.save({'model':model.state_dict(),\n",
    "                        'old2new':old2new,'new2old':new2old,\n",
    "                        'K':K, 'feat_dim':feat_dim}, \"best_linear_probe.pt\")\n",
    "            print(f\"  ↳ New best val acc {best_val:.4f} — saved to best_linear_probe.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79150032-87f4-406c-a546-aa98594a99f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# Section 11a – One-Batch Overfit Sanity Check\n",
    "# ==========================================================\n",
    "xb, yb = next(iter(train_loader))\n",
    "xb, yb = xb.to(device), yb.to(device)\n",
    "\n",
    "_test_opt = torch.optim.SGD(model.head.parameters(), lr=0.05, momentum=0.9)\n",
    "model.train()\n",
    "for step in range(300):\n",
    "    _test_opt.zero_grad(set_to_none=True)\n",
    "    with amp.autocast('cuda', dtype=AMP_DTYPE) if USE_AMP else contextlib.nullcontext():\n",
    "        out = model(xb); loss = crit(out, yb)\n",
    "    loss.backward(); _test_opt.step()\n",
    "    if step % 50 == 0:\n",
    "        acc = (out.argmax(1) == yb).float().mean().item()\n",
    "        print(f\"[1-batch] step {step:3d} | loss {loss.item():.3f} | acc {acc:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "684cb06d",
   "metadata": {},
   "source": [
    "### Section 12 - Test Set Evaluation\n",
    "Runs the final trained model against the held-out test split, generating macro F1 scores, a classification report, and a confusion matrix for post-training analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cef1b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================\n",
    "# Section 12 – Test Set Evaluation\n",
    "# =========================================\n",
    "@torch.no_grad()\n",
    "def evaluate_loader(loader):\n",
    "    model.eval()\n",
    "    total_loss, total_correct, seen = 0.0, 0, 0\n",
    "    all_preds, all_tgts = [], []\n",
    "    for x, y in loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        logits, loss = _forward(x, y)\n",
    "        preds = logits.argmax(1)\n",
    "        total_loss   += loss.item() * y.size(0)\n",
    "        total_correct += (preds == y).sum().item()\n",
    "        seen += y.size(0)\n",
    "        all_preds.append(preds.detach().cpu())\n",
    "        all_tgts.append(y.detach().cpu())\n",
    "    import torch as _t\n",
    "    return (total_loss/seen, total_correct/seen,\n",
    "            _t.cat(all_preds).numpy(), _t.cat(all_tgts).numpy())\n",
    "\n",
    "# If you have a test_loader, run it; otherwise, run on val.\n",
    "loader_to_eval = globals().get(\"test_loader\", val_loader)\n",
    "\n",
    "te_loss, te_acc, te_preds, te_tgts = evaluate_loader(loader_to_eval)\n",
    "print(f\"[Test] loss {te_loss:.4f} | acc {te_acc:.4f}\")\n",
    "\n",
    "# Optional: basic classification report & confusion matrix\n",
    "try:\n",
    "    from sklearn.metrics import classification_report, confusion_matrix\n",
    "    print(\"\\nClassification report (new-index space):\")\n",
    "    print(classification_report(te_tgts, te_preds, digits=3, zero_division=0))\n",
    "except Exception as e:\n",
    "    print(\"sklearn metrics unavailable:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25fc66f3",
   "metadata": {},
   "source": [
    "### Section 13 - Calibrate Probabilities\n",
    "Performs temperature scaling on validation logits to calibrate predicted probabilities and saves the resulting temperature for downstream inference.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f53423",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================\n",
    "# 13) TEMPERATURE SCALING (Calibrate)\n",
    "# ===================================\n",
    "def temperature_scale(logits, T):\n",
    "    return logits / T\n",
    "\n",
    "def find_temperature(val_loader):\n",
    "    net.eval()\n",
    "    logits_list, y_list = [], []\n",
    "    with torch.no_grad():\n",
    "        for x,y in val_loader:\n",
    "            x = x.to(device)\n",
    "            logits,_ = net(x, None)\n",
    "            logits_list.append(logits.cpu().numpy())\n",
    "            y_list.append(y.numpy())\n",
    "    L = np.concatenate(logits_list); Y = np.concatenate(y_list)\n",
    "\n",
    "    T = 1.0\n",
    "    for _ in range(100):\n",
    "        # simple 1D search via gradient-free update\n",
    "        temps = np.linspace(0.5, 3.0, 26)\n",
    "        nll = []\n",
    "        for t in temps:\n",
    "            z = torch.tensor(L/t).float()\n",
    "            y = torch.tensor(Y).long()\n",
    "            nll.append(F.cross_entropy(z, y).item())\n",
    "        T = float(temps[int(np.argmin(nll))])\n",
    "    return T\n",
    "\n",
    "T = find_temperature(val_loader)\n",
    "print(\"Best temperature:\", T)\n",
    "\n",
    "os.makedirs(CONFIG[\"OUT_DIR\"], exist_ok=True)\n",
    "with open(os.path.join(CONFIG[\"OUT_DIR\"], \"calibration.json\"), \"w\") as f:\n",
    "    json.dump({\"temperature\": T}, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "995eed1d",
   "metadata": {},
   "source": [
    "### Section 14 - Inference Helpers\n",
    "Supplies convenience functions to load single images, apply optional sheet-based masking, and return top-k predictions with metadata for interactive use or deployment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bebe7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# Section 14 – Inference Helpers\n",
    "# ==========================================\n",
    "import torch\n",
    "\n",
    "def argmax_to_original_id(pred_new_idx):\n",
    "    \"\"\"\n",
    "    Convert predicted new-index classes (0..K-1) back to original 424-id labels.\n",
    "    \"\"\"\n",
    "    if torch.is_tensor(pred_new_idx):\n",
    "        pred_new_idx = pred_new_idx.detach().cpu().tolist()\n",
    "    return [new2old[int(i)] for i in pred_new_idx]\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict_images(img_batch_tensor):\n",
    "    \"\"\"\n",
    "    img_batch_tensor: (B,3,H,W) normalized as in training.\n",
    "    Returns:\n",
    "      preds_new: tensor of shape (B,) in 0..K-1\n",
    "      preds_orig: list of original class ids (subset of 424 space)\n",
    "      logits: raw logits (B,K)\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    x = img_batch_tensor.to(device)\n",
    "    logits, _ = _forward(x, torch.zeros(x.size(0), dtype=torch.long, device=device))\n",
    "    preds_new = logits.argmax(1)\n",
    "    preds_orig = argmax_to_original_id(preds_new)\n",
    "    return preds_new.cpu(), preds_orig, logits.cpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2205a3a",
   "metadata": {},
   "source": [
    "### Section 15 - Save Metadata Artefacts\n",
    "Exports label mappings, sheet groupings, and other metadata so future sessions can decode predictions without recomputing the taxonomy processing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f3a555",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================\n",
    "# 15) SAVE LABEL MAP & METRICS\n",
    "# =============================\n",
    "out = {\n",
    "    \"id_to_idx\": id_to_idx,\n",
    "    \"idx_to_info\": idx_to_info,\n",
    "    \"sheet_to_ids\": {k:list(v) for k,v in sheet_to_ids.items()},\n",
    "    \"image_size\": CONFIG[\"IMAGE_SIZE\"],\n",
    "}\n",
    "with open(os.path.join(CONFIG[\"OUT_DIR\"], \"label_map.json\"), \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(out, f, indent=2, ensure_ascii=False)\n",
    "print(\"Saved label_map.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77995c5c",
   "metadata": {},
   "source": [
    "### Section 16 - Export to ONNX (Optional)\n",
    "Shows how to export the trained PyTorch model to ONNX for serving in inference runtimes that expect the format.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f72403",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================\n",
    "# 16) OPTIONAL: ONNX EXPORT\n",
    "# ========================\n",
    "example = torch.randn(1,3,CONFIG[\"IMAGE_SIZE\"],CONFIG[\"IMAGE_SIZE\"]).to(device)\n",
    "torch.onnx.export(net, (example, None), os.path.join(CONFIG[\"OUT_DIR\"], \"model_best.onnx\"),\n",
    "                  input_names=[\"image\",\"targets\"], output_names=[\"logits\",\"loss\"],\n",
    "                  opset_version=17, do_constant_folding=True, verbose=False)\n",
    "print(\"Exported ONNX.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d53d8b6",
   "metadata": {},
   "source": [
    "### Section 17 - Run Summary\n",
    "Prints a concise recap of the paths, image size, and compute device used for the current run, making experiment tracking easier.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84fce760",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================\n",
    "# 17) RUN SUMMARY\n",
    "# ====================\n",
    "print(\"\\n================ SUMMARY ================\")\n",
    "print(\"Images dir       :\", CONFIG[\"IMAGES_DIR\"])\n",
    "print(\"CSV path         :\", CONFIG[\"CSV_PATH\"])\n",
    "print(\"Labels JSON      :\", CONFIG[\"LABELS_JSON\"])\n",
    "print(\"Output dir       :\", CONFIG[\"OUT_DIR\"])\n",
    "print(\"Image size       :\", CONFIG[\"IMAGE_SIZE\"])\n",
    "print(\"Device           :\", device)\n",
    "print(\"=========================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "283760bb",
   "metadata": {},
   "source": [
    "### Appendix - Optional Image Inspection\n",
    "Commented example code for plotting a handful of sample images with PIL and Matplotlib. Uncomment when you need a quick visual check of the synced dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e46e38",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# from pathlib import Path\n",
    "# from PIL import Image\n",
    "# import matplotlib.pyplot as plt\n",
    "# samples = [\n",
    "#     Path(CONFIG[\"IMAGES_DIR\"]) / \"17-034_page6_img3.png\",\n",
    "#     Path(CONFIG[\"IMAGES_DIR\"]) / \"17-057-4_page17_img3.png\",\n",
    "#     Path(CONFIG[\"IMAGES_DIR\"]) / \"17-057-16_page16_img2.png\",\n",
    "#     Path(CONFIG[\"IMAGES_DIR\"]) / \"17-067_page21_img1.png\",\n",
    "#     Path(CONFIG[\"IMAGES_DIR\"]) / \"19-025_page24_img3.png\",\n",
    "#     Path(CONFIG[\"IMAGES_DIR\"]) / \"21-009_page14_img2.png\",\n",
    "# ]\n",
    "# ]\n",
    "# for p in samples:\n",
    "#     try:\n",
    "#         plt.figure(); plt.imshow(Image.open(p)); plt.axis('off'); plt.title(Path(p).name)\n",
    "#     except Exception as e:\n",
    "#         print(\"Missing:\", p)\n"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m133",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m133"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
